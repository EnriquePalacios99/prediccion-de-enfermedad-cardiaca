"""
Examen de Minería de Datos: Predicción de Enfermedad Cardíaca
Duración total: 1 h 30 min  ·  Archivo: heart_cleveland_upload.csv

───────────────────────────────────────────────────────────────────────────────
PARTE 1 · ANÁLISIS CONCEPTUAL
───────────────────────────────────────────────────────────────────────────────
1. Objetivo comercial
   Reducir re-ingresos y costes hospitalarios detectando de forma temprana a
   pacientes con riesgo de cardiopatía, optimizando recursos (UCI, fármacos).

2. Objetivo de minería de datos
   Construir un modelo que, dados 13 parámetros clínicos, prediga la variable
   `condition` (0 = sano, 1 = enfermo).

3. Tipo de problema
   Clasificación binaria.

4. Ejemplos de variables
   • Numérica: age, chol, thalach, oldpeak
   • Categórica: cp, thal, slope
   • Binaria: sex, fbs
   • Ordinal: ca (n.º vasos coloreados 0-3)

5. Significado de cp
   Tipo de dolor torácico (0 = típico anginoso, 1 = angina atípica,
   2 = dolor no anginoso, 3 = asintomático); indicador clínico de isquemia.

───────────────────────────────────────────────────────────────────────────────
PARTE 2 · IMPLEMENTACIÓN TÉCNICA (Python 3, Pandas, Scikit-learn, Seaborn)
───────────────────────────────────────────────────────────────────────────────
"""

# 6. Carga del dataset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix,
                             RocCurveDisplay)

pd.set_option("display.max_columns", None)

df = pd.read_csv("heart_cleveland_upload.csv")  # Ajusta ruta si es necesario
print("Primeras 5 filas:")
display(df.head())
print(f"Dimensiones: {df.shape}")

# 7. Análisis exploratorio rápido
print("\nResumen estadístico:")
display(df.describe().T)

print("\nValores nulos por columna:")
print(df.isna().sum())

# Histogramas
df.hist(figsize=(14, 10), bins=20)
plt.suptitle("Distribución de variables numéricas", y=1.02, fontsize=16)
plt.tight_layout()
plt.show()

# Matriz de correlación
corr = df.corr(numeric_only=True)
plt.figure(figsize=(11, 8))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Matriz de correlación")
plt.show()

# 8. Preparación de datos
X = df.drop(columns=["condition"])
y = df["condition"]

cat_cols = ["cp", "thal", "slope"]
num_cols = [c for c in X.columns if c not in cat_cols]

preprocess = ColumnTransformer(
    transformers=[
        ("num", "passthrough", num_cols),
        ("cat", OneHotEncoder(drop="first"), cat_cols)
    ]
)

print("\nBalance de clases:")
print(y.value_counts(normalize=True).rename("proporción").to_frame())

# 9. División entrenamiento / prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, stratify=y, random_state=42
)
print(f"\nTamaños  →  Train: {X_train.shape},  Test: {X_test.shape}")

# 10. Entrenamiento (Regresión Logística por interpretabilidad)
clf = Pipeline(steps=[
    ("prep", preprocess),
    ("model", LogisticRegression(max_iter=1000, solver="liblinear"))
])
clf.fit(X_train, y_train)

# 11. Evaluación
y_pred = clf.predict(X_test)
y_prob = clf.predict_proba(X_test)[:, 1]

metrics = {
    "Accuracy":  accuracy_score(y_test, y_pred),
    "Precision": precision_score(y_test, y_pred),
    "Recall":    recall_score(y_test, y_pred),
    "F1-score":  f1_score(y_test, y_pred),
    "ROC-AUC":   roc_auc_score(y_test, y_prob)
}
print("\nMétricas de desempeño:")
for k, v in metrics.items():
    print(f"{k:<9}: {v:0.3f}")

print("\nMatriz de confusión:")
print(confusion_matrix(y_test, y_pred))

RocCurveDisplay.from_predictions(y_test, y_prob)
plt.show()

# 12. Conclusión breve
print(
    "\nConclusión:\n"
    "• El modelo inicial logra un ROC-AUC ≈ {0:.2f}, lo cual es prometedor.\n"
    "• Variables como cp, thalach, oldpeak y ca muestran alta influencia.*\n"
    "• Futuro: probar ensambles (Random Forest, XGBoost), balancear clases\n"
    "  con SMOTE y emplear SHAP para explicabilidad clínica."
    .format(metrics["ROC-AUC"])
)
